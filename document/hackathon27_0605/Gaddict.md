# 推薦システム 輪読会@エムスリー
## 第1章 はじめに
## 西場 正浩 @m_nishiba

---
## 第1章 はじめに
- 推薦システムとは、様々な分脈においてユーザーに「最良」のアイテムを推薦するプログラム
- 「最良」の定義は目的によって変わる。
- 推薦システム例:
	- ECサイトでの商品推薦(Amazon)
	- ニュースサイトの記事推薦(Gunosy、Archimedes)

### 典型的な入力
- ユーザー
- アイテム
- コンテキスト（分脈、いつ／デバイスなど）
- フィードバック（アイテムに対するユーザーの反応）
 	- Explicit: レビューなど
 	- Implicit: クリックなど
    - クリックしてないから嫌いというわけではない。気づいてないだけかも

---
### 推薦システムの計算
- オフライン計算(バッチ計算、Archimedes)
  - こない人のぶんも計算しないといけないから計算量が多くなる
- リアルタイム計算(リアルタイム計算、Bourbaki)
- ハイブリッド計算(2つの組合せ)

### 更新頻度
- 寿命が短いアイテム(ニュース) → 頻繁に行う（数分ごと）
  - Archimedesは30分おきくらい
- 寿命が長いアイテム(アイテム) → 頻度は低くてよい（日ごと）
  - 映画とか

---
## 1.1 ウェブアプリケーションへの推薦システム導入時の留意点
### 開発前に考える重要な問い
- 取得可能な素性は何か？
  - 真剣に考えた方が良い
  - こんなデータがあれば良いものだせるじゃんとか
  - 与えられたデータ以外も検討するべき
  - Garbage IN Garbage OUT ゴミを与えてもゴミしか出てこない
- 最適化の目的は何か？
	- 短期: クリック数、収益
	- 長期: サイトに費やされた時間、継続率の向上
    - こっちの方を意識するのが難しい

---
## 1.1.1 アルゴリズム上の工夫
### 4つのタスクを実行するための工夫が必要
- コンテンツとフィルタリングと理解
	- 低品質のコンテンツをふるい落とす
- ユーザー特性モデル
	- 登録情報や行動ログから作成する。
  - データそのものではなく、活用しやすいデータに加工すべき
- スコアリング
	- ユーザー／アイテム特性を使って、コンテキストにおける価値を最大化するスコアリングを行う。
  - いろんなスコアをつける観点がある
- ランキング
	- 推薦するアイテムの順位付け。単純な方法では単一のスコアリングをもとに順位づけする。
  - いろんなスコアをいい感じに組み合わせたりする

### 注
- アイテム特性を抽出する方法はアイテムにより大きく異なる
	- 第2章で簡単に解説する
- ユーザー特性を抽出する方法には触れない
- ユーザーとアイテムの両方の特性を過去のデータから自動的に「学習」する手法を主に解説する。

---
## 1.1.2 最適化指標
### 考慮すべき2つのこと
1. どの指標を最適化するか？
	- 例: 総クリック数、総収益、総売上
	- 多くの場合、単一指標を用いる。
	- 複数指標の場合もある。
		- 例: ユーザーエンゲージメントに対して製薬のあるコンテンツリンクの合計クリックを最大化する。
			- バウンスクリック数をある閾値以下にする。
		- 多様性やセレンディピティの確保など。
2. 最適化問題に投入するスコアを決める


---
## 1.1.3 探索と活用のトレードオフ
- 応答率: CTR、レイティング、シェア率、いいね数を適切に重み付けしたもの
- 正確に推定するために、各アイテムに対する応答データを収集する: **探索(exploration)**
- 推定応答率の高いアイテムを活用し最適化する: **活用(exploitation)**
- 探索を増やすと機会損失になる、減らすと推定精度が下がる。
- 探索と活用については、第3章、第6~8章で扱う。

- 探索
  - これ好き？って出して反応を見る
  - 多すぎると興味ないやつを推薦し続けて機会損失になる
  - 決め方は色々良い方法が研究されている

---
## 1.1.4 推薦システムの評価
### 開発フェーズに応じて性能評価が必要
### テスト方法
- デプロイ前フェーズ
	- 過去のデータを使ってテストを行う。アルゴリズムに対するユーザーの反応を直接的に見ることはできない。
- デプロイ後フェーズ
	- オンラインテスト。実際に本番に出してA/Bテスト等を行う。
### 評価方法
- スコアリングの評価
	- 予測数値との二乗誤差など
- ランキングの評価
	- CTRやコンテンツの閲覧時間

---
## 1.1.5 推薦と検索: プッシュとプル
- プルモデル
	- ユーザーの意図が明確
		- 例: Web検索など
    - パーソナルサーチ
- プッシュモデル
	- ユーザーの意図が不明確
		- 例: ポータルページでのニュース記事の推薦
- 組合せ
	- 例: 読んでいる記事の関連記事の推薦

#### 注
- 本書ではプルモデルはあまり扱わない。

---
## 1.2 シンプルなスコアリングモデル: Most-Popular推薦
- 総クリック数を最大化すること目的とする。
- 全ユーザーに同一のものを推薦する。
- より洗練された手法のため強力なベースラインになる。
  - こいつに勝てないレコメンドはいらない
  - だからこそこの手法をしっかり学ぶ必要がある

### 問題例
- Yahooのトップページで記事をリコメンドする。
- 記事$i$の$t$時点でのCTRを $p_{it}$ とする。
- $t$時点の訪問に対して $i^*_t=\text{argmax}_i p_{it}$ を選べばよい。
- しかし、実際には $p_{it}$ は不明であり、データから推測した $\hat{p}_{it}$ を使う。

### 疑問
- 推定CTRが最大のアイテムを配信するだけで十分か?
- $\hat{i}^*_t=\text{argmax}_i \hat{p}_{it}$ は $i^*_t$ をよく近似しているか？

### 反例
- $\hat{p}_{1t} \sim N(0.01, 0.005)$, $\hat{p}_{2t} \sim N(0.015, 0.001)$
- $P(\hat{p}_{1t} > \hat{p}_{2t}) = 0.47$ と間違ったほうを選ぶ可能性が高い。
- 理由はアイテム1の分散がアイテム2の分散より大きいから。

### 方針
- $\epsilon$-greedy法等を用いる。
	- 探索と活用のバランスを調整する。

# 推薦システム 輪読会@エムスリー
## 第2章 古典的手法
## 西場 正浩 @m_nishiba

---
## 第2章 古典的手法
### 推薦システムが一般的に使う情報
- アイテムについての既知の情報(2.1節)
- ユーザについての既知な情報(2.2節)
- 過去のユーザー・アイテム間の相互作用(クリックした？)

### 古典的な手法
- ユーザーiとアイテムjの素性ベクトルの類似度(2.3節)
- アイテムjに「類似している」アイテムへのユーザーiの過去の応答／その逆(2.4節)
- 上記の組み合わせ(2.5節)

### 注
- 古典的な手法はベースラインとして使える。
- 手法の詳細
  - [Adomavicius and Tuzhilin (2005)](http://pages.stern.nyu.edu/~atuzhili/pdf/TKDE-Paper-as-Printed.pdf)
  - Jannach et al. (2010)
  - Ricci et al. (2011)

### 記法
- ユーザーiの素性ベクトル: $x_i$
- アイテムjの素性ベクトル: $x_j$
- ユーザーiのアイテムjのレイティング: $y_{ij}$

---
## 2.1 アイテム素性ベクトル
- 素性ベクトルの構成方法はアイテムによって異なる（画像、テキスト、属性情報）
- 一般的な方法
  - カテゴリ化 (2.1.1項)
  - bag-of-words (2.1.2項)
  - トピックモデリング (2.1.3項)
  - それ以外 (2.1.4項)
---
## 2.1.1 カテゴリ化
- アイテムをカテゴリに分類する手法
- アイテムの分類手法
  - 人間がラベルを付ける
  - 統計的手法を使う（教師あり学習）
- 素性ベクトル
  - one-hotベクトル
    - 1つだけ1になって他は0になる
  - 重み付けベクトル
    - $||x_j||_1=1$、$||x_j||_2=1$ と正規化することもある。
    - 正規化の利点は実証的評価が必要

---
## 2.1.2 bag-of-words
### bag-of-wordsの3つの一般的な方法
- 2値表現:
  - アイテム$j$が$l$番目の単語を含んでいれば$x_{j,l}=1$、それ以外は$x_{j,l}=0$
- 単語頻度(TF: term frequency):
  - アイテム$j$に$l$番目の単語が現れた回数。$x_{j,l}=\text{TF}(j, l)$
- 単語頻度-逆文書頻度(TF_IDF: term frequency - inverse document frequency)
  - $DF(l)$: アイテムコーパス無いのアイテムで$l$番目の単語を含む割合
  - $IDF(l)=\log(1/DF(l))$
  - $x_{j,l}=\text{TF}(j, l) \cdot IDF(l)$
- 最後に $||x_j||_2=1$ と正規化する。

### 関連する話題
- アイテムの類似度
  - 正規化された素性ベクトルの内積(2つのベクトルのコサインに等しい)。コサイン類似度と呼ぶ。
- スパースなデータ形式
  - 素性ベクトルの多くの要素は0になる。0でない要素のインデックスと値だけを保持することで使用メモリを削減できる。
- 句とエンティティ
  - 単語だけでなく、n-グラムを使用することもできる。
- 次元削減
  1. 類義語拡張:
    - 類義語を追加する。素性ベクトルの要素が0→1に変わり、スパース性が下がる。
    - 例: アイテム内に「勤勉」が含まれていたとき、「熱心」「克明」を追加する。
  2. 素性選択:
    - すべての単語が有用とは限らないので、過剰に出現頻度が高い/低い単語を無視する。
  3. 特異値分解:
    - 全アイテムの素性を表す$X$を特異値分解する($X$の$j$行は$x_j$)
    - 高次元空間から低次元空間への線形写像に基づく
  4. ランダム射影:
    - 特異値分解より簡単かつ効果的な方法としてランダム線形射影がある。

---
## 2.1.3 トピックモデリング
- テキストベースの教師なし分類手法の研究が進んでいる。
- 例: 潜在ディリクレ分配（LDA)

---
## 2.1.4 その他のアイテム素性ベクトル
- アイテム素性はアプリケーションに特化していることが多い。
- ドメイン知識、経験、アプリケーションの洞察が必要

### 例
- 出典
- 場所
- 画像
- オーディオ

---
## 2.2 ユーザー素性ベクトル
### 種類
- 公表されているユーザープロファイル
- ユーザーとアイテムの相互作用(クリックした？)
- 推薦システム内で利用可能なユーザー関連情報

---
## 2.2.1 公表されているユーザープロファイル
### ユーザーの登録情報の利用
- 人口統計
  - 年齢、性別、職業、教育水準、地域、etc
- 興味/関心
  - 興味や関心のあるトピック、キーワードを登録してもらう
  - ユーザーの関心を引き出すプロセスを、自然に、負担なく、楽しくすることは重要な課題

---
## 2.2.2 アイテム素性ベクトルの利用
- ユーザーが過去に評価(レイティング、クリック、購入)したアイテムの素性ベクトルを利用する。
  - ユーザー$i$と相互作用があったアイテムの集合を $\mathcal{J}_i$ とする。
  - $x_i = F(\{x_j: j \in \mathcal{J}_i\})$
  - $F$は平均や加重平均等を使う。

---
## 2.2.3 その他のユーザー素性ベクトル
- 現在位置
- 利用回数ベースの素性ベクトル
- 検索履歴
- アイテム集合

---
## 2.3 素性ベクトルベースの手法
- ユーザーとアイテムの素性ベクトルが与えられたとき、親和性を測るスコアリング関数 $s(x_i, x_j)$ を設計することでアイテムの順位付けができる。
- スコアリング関数の学習方法
  - 教師あり学習
  - 教師なし学習

---
## 2.3.1 教師なし学習
- ユーザー素性ベクトルとアイテム素性ベクトルが同一ベクトル空間の点の場合
  - 例: ユーザーとアイテムが同じコーパスからのbag-of-words
- スコアリング関数例:
  - コサイン類似度
  - Okapi BM25
    - TFIDFベース
  - Jaccard係数
    - 2値表現の素性ベクトルに対して使える。
    - 2つのベクトルで共通する集合の要素数を2つのベクトル内の全要素数で割る
    - $J(A, B) = \frac{|A \cap B|}{|A \cup B|}$

---
## 2.3.2 教師あり学習
- 観測されたレイティングを教師データとし、観測していないレイティングを予測するようにモデルを学習させる。
- 例: 総線形回帰モデル
  - $s_{ij} = s(x_i, x_j) = x'_i A x_j$
  - $A$が訓練対象

---
## レイティングのタイプ
- 観測された(ユーザー$i$、アイテム$j$)の集合: $\Omega$
- 観測されたレイティング: $Y=\{y_{ij}:(i,j) \in \Omega\}$

### バイナリレイティング(ロジスティックモデル)
- レイティング $\{0, 1\}$ (クリックなど) がロジスティック応答モデルに従うとする。
- $y_{ij} \sim \text{Bernoulli}((1 + \exp(-s_{ij}))^{-1})$
- 対数尤度: $\log P(Y|A) = - \sum_{i,j \in \Omega} \log(1 + \exp(-y_{ij} s_{ij}))$
- 詳細は Hastie et al. (2009)

## 数値型レイティング(ガウシアンモデル)
- レイティング(実数の点数など) がガウス応答モデルに従うとする。
- $y_{ij} \sim N(s_{ij}, \sigma^2)$
- 対数尤度: $\log P(Y|A) = - \frac{1}{2 \sigma^2} \sum_{i,j \in \Omega} (y_{ij} - s_{ij})^2$
- 詳細は Hastie et al. (2009)

## 順序レイティング（累積ロジットモデル）
- レイティングがk-段階スケールで評価される。
- 例えば、5段階評価の場合、5と4の差は3と2の差よりも小さい可能性がある。
- この場合、順序回帰が適切。
- $y_{ij} \sim \text{Multinomial}(\pi_{ij,1},...,\pi_{ij,R})$
- $\pi_{ij,r}$ はユーザー$i$がアイテム$j$に評価$r$を与える確率。
- このとき$P(Y_{ij} > r)$ の対数オッズが $s_{ij} - \theta_r$ であると仮定
  - $\text{logit}(P(Y_{ij}>r))=\log\frac{P(Y_{ij}>r)}{1-P(Y_{ij}>r)}=s_{ij}-\theta_r$
- ここまでの仮定より
  - $P(Y_{ij}>r)=\sum_{q=r+1}^R \pi_{ij,q}=(1+\exp(-(s_{ij}=\theta_r)))^{-1}$
- $f_{ij}(r, \theta, A):=P(Y_{ij}>r)$ と定義すると対数尤度は
  - $\log P(Y|A) = \sum_{i,j \in \Omega} \log(f_{ij}(y_{ij} - 1, \theta, A) - f_{ij}(y_{ij}, \theta, A))$

## 共起嗜好性スコア
- ユーザー$i$がアイテム$j$をアイテム$l$より好むかを観測できる（e.g. $j$をクリックしたが、$l$をクリックしていない）
- このときのレイティングを $y_{ijl} \in \{+1, -1\}$ と表す
- 好み具合は $s_{ij}-s_{il}$ に比例すると仮定
  - $y_{ijl}\sim\text{Bernoulli}((1 + \exp(-(s_{ij}-s_{il})))^{-1})$
- 対数尤度: $\log P(Y|A) = - \sum_{i,j,l \in \Omega} \log(1 + \exp(-y_{ij} (s_{ij} - s_{il})))$

## 正則化付き最尤推定
- $\text{argmax}_{A,\theta} (\log P(Y|A,\theta) - \lambda r(A))$
- 正則化項 $r(A)$ を入れることにより過学習を抑えることができる。
- 座標降下法や確率的勾配降下法で解くことができる。

## 2.3.3 コンテキスト情報
- ユーザーのレイティングは、ユーザーとアイテムの素性ベクトル以外にも依存する。
  - 表示位置
  - 時刻
  - 曜日
  - デバイス
- コンテキストの素性ベクトルを $z_{ij}$ とする。
  - $s_{ij} = s(x_i, x_j) = x'_i A x_j + b' z_{ij}$

## 2.4 協調フィルタリング
- ベースとなるアイデア
  - 過去に同じようなレイティングをしているユーザー同士は興味が似ている可能性が高い。

## 2.4.1 ユーザー間の類似度に基づいた手法
- ユーザー $i$ のアイテム $j$ の評価 $s_{ij}$ を予測する。
- ユーザー $i$ に類似しており、アイテム $j$ を評価したユーザーの集合: $I_j(i)$
  - $s_{ij} = \bar{y}_i + \frac{\sum_{l \in I} w(i, j) (y_{lj} - \bar{y}_l)}{\sum_{l \in I} |w(i, j)|}$

### 類似度関数
- ピアソン相関
- 近傍選択
- 重み付け

## 2.4.2 アイテム間の類似度に基づいた手法
- ユーザー $i$ のアイテム $j$ の評価 $s_{ij}$ を予測する。
- ユーザー $i$ に評価されたアイテム $j$ に似ているアイテムの集合: $J_i(j)$
  - $s_{ij} = \bar{y}_j + \frac{\sum_{l \in J} w(j, l) (y_{il} - \bar{y}_l)}{\sum_{l \in J} |w(j, l)|}$

## 2.4.3 行列分解
- ユーザーとアイテムに対して潜在因子(latent factor)を導入。$n$ 次元のベクトル
- $s_{ij}=u'_i v_j$
- (本書では素性ベクトルは既知。潜在因子は学習対象とする。)
- 潜在因子を学習させるため、下記の最適化問題を解く。
  - $\text{argmin}_{u, v} \sum_{i,j \in \Omega} (y_{ij} - u'_i v_j)^2$
### 正則化
- 観測データよりパラメータ数のほうが小さくなるようにモデル化できる。
- 観測データが少ない場合、予測精度が下がる可能性がある。
- 一般的に使用させる方法として、L2ノルムによる正則化項を目的関数に加える
- $\text{argmin}_{u, v} \sum_{i,j \in \Omega} (y_{ij} - u'_i v_j)^2 + \lambda_1 \sum ||u_i||^2 + \lambda_2 \sum ||v_j||^2$

### 最適化メソッド
- 最適解は一意でない。
  - e.g. $u$と$v$の符号反転させる

#### 交互最小二乗法(ALS: alternating least square)
- $u$を固定すると$v$についての最小二乗線形回帰問題になる。逆もしかり。
- 交互に最小二乗線形回帰問題を解くことを繰り返すことで推定値を得る。

#### 確率的勾配降下法

## 2.5 ハイブリッド法
- 協調フィルタリング
  - ウォームスタートだと有利
- 素性ベクトルベースの手法
  - コールドスタートだと有利

### アンサンブル
- 線形結合
- 投票方式

### 協調フィルタリングを素性ベクトルとして扱う
- 新しい素性ベクトルとして使う

### 類似性に基づいた協調フィルタリングにおける素性ベクトルベースの類似の使用
1. レイティングの類似性
2. 素性ベクトルの類似性
3. 2つの線形結合

### 人工的素性ベクトルベースのレイティングによる協調フィルタリングの補間
- コールドスタートに対処するために新しいアイテム（ユーザー）の評価を人工的に作る。
  - 素性ベクトルベースから予測された評価を使用する。

## 2.6 まとめ
- アプリケーションに適した方法を開発する必要がある
  - 利用可能な素性情報
  - アイテムプールのサイズ
  - アイテムの生存期間
  - データのスパースネス
  - コールドスタートの度合い
